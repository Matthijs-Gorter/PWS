\babel@toc {dutch}{}\relax 
\contentsline {chapter}{Voorwoord}{I}{chapter*.1}%
\contentsline {chapter}{Inhoudsopgave}{II}{chapter*.2}%
\contentsline {chapter}{\numberline {1}Inleiding}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Doel van het onderzoek}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Onderzoeksvragen}{2}{section.1.2}%
\contentsline {section}{\numberline {1.3}Hypothese}{2}{section.1.3}%
\contentsline {section}{\numberline {1.4}Relevantie van het Onderzoek}{2}{section.1.4}%
\contentsline {chapter}{\numberline {2}Theoretisch Kader}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}Fundamentele Elementen van MDP's}{3}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Toestandsruimte}{3}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Actieruimte}{3}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Beloningsfunctie}{3}{subsection.2.1.3}%
\contentsline {section}{\numberline {2.2}Markov-eigenschap en Overgangsdynamiek}{3}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}De Markov-eigenschap}{3}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Overgangswaarschijnlijkheidsfunctie}{4}{subsection.2.2.2}%
\contentsline {section}{\numberline {2.3}Beleid en Verwachte Waarden}{4}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Beleid}{4}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Verwachte Waarden}{4}{subsection.2.3.2}%
\contentsline {section}{\numberline {2.4}Leerparameters in Reinforcement Learning}{4}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Leerpercentage}{4}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Kortingsfactor}{5}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Exploratieparameter}{5}{subsection.2.4.3}%
\contentsline {section}{\numberline {2.5}Waarde-functies}{5}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Toestandswaarde-functie}{5}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Q-functie}{6}{subsection.2.5.2}%
\contentsline {chapter}{\numberline {3}Kenmerken van specifieke Algoritmes}{7}{chapter.3}%
\contentsline {section}{\numberline {3.1}Q-Learning}{7}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Proces}{7}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Beperkingen}{7}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Deep Q-Network}{9}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Neuraal Netwerk}{9}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Proces}{10}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Verbeteringen op Klassiek Q-learning}{10}{subsection.3.2.3}%
\contentsline {subsection}{\numberline {3.2.4}Voordelen en Beperkingen}{10}{subsection.3.2.4}%
\contentsline {subsection}{\numberline {3.2.5}Toepassingen}{12}{subsection.3.2.5}%
\contentsline {section}{\numberline {3.3}Deep Policy Gradient}{12}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Actor-Critic model}{12}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Proces}{13}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Toepassingen}{14}{subsection.3.3.3}%
\contentsline {chapter}{\numberline {4}Kenmerken van specifieke Computerspellen}{15}{chapter.4}%
\contentsline {section}{\numberline {4.1}Indeling en Strategische Diepgang van Spellen}{15}{section.4.1}%
\contentsline {section}{\numberline {4.2}Indeling van Spellen}{16}{section.4.2}%
\contentsline {section}{\numberline {4.3}Strategische Diepgang}{16}{section.4.3}%
\contentsline {section}{\numberline {4.4}Beslissingsdynamiek en Tijdgevoeligheid}{16}{section.4.4}%
\contentsline {section}{\numberline {4.5}Complexiteit}{16}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Regels en Beperkingen}{17}{subsection.4.5.1}%
\contentsline {subsubsection}{Spellen met veel regels en vaste patronen}{17}{subsection.4.5.1}%
\contentsline {subsubsection}{Spellen met weinig regels en veel vrijheid}{17}{subsection.4.5.1}%
\contentsline {section}{\numberline {4.6}Dynamiek en Tijdgevoeligheid}{17}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Turn-based spellen}{17}{subsection.4.6.1}%
\contentsline {subsection}{\numberline {4.6.2}Realtime spellen}{17}{subsection.4.6.2}%
\contentsline {section}{\numberline {4.7}Beloningsstructuur}{18}{section.4.7}%
\contentsline {subsection}{\numberline {4.7.1}Directe beloningen}{18}{subsection.4.7.1}%
\contentsline {subsection}{\numberline {4.7.2}Cumulatieve beloningen}{18}{subsection.4.7.2}%
\contentsline {chapter}{\numberline {5}De invloed van spelkenmerken op Reinforcement Learning-Algoritmes}{19}{chapter.5}%
\contentsline {section}{\numberline {5.1}Strategische Diepgang}{19}{section.5.1}%
\contentsline {section}{\numberline {5.2}Regels en Beperkingen}{19}{section.5.2}%
\contentsline {section}{\numberline {5.3}Dynamiek en Tijdgevoeligheid}{20}{section.5.3}%
\contentsline {section}{\numberline {5.4}Beloningsstructuur}{20}{section.5.4}%
\contentsline {section}{\numberline {5.5}Complexiteit van de Toestandsruimte}{21}{section.5.5}%
\contentsline {section}{\numberline {5.6}Onvoorspelbaarheid}{21}{section.5.6}%
\contentsline {chapter}{\numberline {6}Onderzoeksmethoden}{22}{chapter.6}%
\contentsline {section}{\numberline {6.1}Technische Uitvoering}{22}{section.6.1}%
\contentsline {section}{\numberline {6.2}Verzamelen van Gegevens}{22}{section.6.2}%
\contentsline {section}{\numberline {6.3}Optimalisatie van Instellingen}{22}{section.6.3}%
\contentsline {chapter}{\numberline {7}Resultaten}{23}{chapter.7}%
\contentsline {section}{\numberline {7.1}Experimentele Opzet}{23}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Hyperparameters}{23}{subsection.7.1.1}%
\contentsline {section}{\numberline {7.2}Prestatievergelijking: Gemiddelde Score per Episode}{23}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}Samenvatting van Prestaties}{23}{subsection.7.2.1}%
\contentsline {section}{\numberline {7.3}Leerdynamiek: Loss en Entropy}{24}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}Loss-curves}{24}{subsection.7.3.1}%
\contentsline {subsection}{\numberline {7.3.2}Entropy (PPO)}{24}{subsection.7.3.2}%
\contentsline {section}{\numberline {7.4}Gedragsanalyse: Beleid in Actie}{24}{section.7.4}%
\contentsline {subsection}{\numberline {7.4.1}Heatmap van Q-waarden (Q-Learning)}{25}{subsection.7.4.1}%
\contentsline {subsection}{\numberline {7.4.2}Trajectory Plot (DQN vs. PPO)}{25}{subsection.7.4.2}%
\contentsline {section}{\numberline {7.5}Falen en Uitdagingen}{25}{section.7.5}%
\contentsline {section}{\numberline {7.6}Benchmark tegen Menselijke Prestaties}{26}{section.7.6}%
\contentsline {chapter}{\numberline {8}Conclusie}{28}{chapter.8}%
\contentsline {chapter}{\numberline {9}Discussie}{29}{chapter.9}%
\contentsline {chapter}{\numberline {A}Notatie}{30}{appendix.A}%
\contentsline {chapter}{\numberline {B}Logboek}{31}{appendix.B}%
\contentsline {section}{\numberline {B.1}Groepsactiviteiten}{31}{section.B.1}%
\contentsline {section}{\numberline {B.2}Matthijs}{32}{section.B.2}%
\contentsline {section}{\numberline {B.3}Thom}{32}{section.B.3}%
\contentsline {section}{\numberline {B.4}Pepijn}{34}{section.B.4}%
\contentsline {chapter}{Bibliografie}{36}{appendix*.17}%
