@book{10.5555/3312046,
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  title     = {Reinforcement Learning: An Introduction},
  year      = {2018},
  isbn      = {0262039249},
  publisher = {A Bradford Book},
  address   = {Cambridge, MA, USA},
  abstract  = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}

@book{10.5555/1795711,
author = {Millington, Ian and Funge, John},
title = {Artificial Intelligence for Games, Second Edition},
year = {2009},
isbn = {0123747317},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {2nd},
abstract = {Creating robust artificial intelligence is one of the greatest challenges for game developers, yet the commercial success of a game is often dependent upon the quality of the AI. In this book, Ian Millington brings extensive professional experience to the problem of improving the quality of AI in games. He describes numerous examples from real games and explores the underlying ideas through detailed case studies. He goes further to introduce many techniques little used by developers today. The book's associated web site contains a library of C++ source code and demonstration programs, and a complete commercial source code library of AI algorithms and techniques."Artificial Intelligence for Games - 2nd edition" will be highly useful to academics teaching courses on game AI, in that it includes exercises with each chapter. It will also include new and expanded coverage of the following: AI-oriented gameplay; Behavior driven AI; Casual games (puzzle games). * The first comprehensive, professional tutorial and reference to implement true AI in games written by an engineer with extensive industry experience.* Walks through the entire development process from beginning to end.* Includes examples from over 100 real games, 10 in-depth case studies, and web site with sample code.}
}

@techreport{tang-2021,
  author = {Tang, Yunhao},
  title  = {{Reinforcement Learning: New Algorithms and An Application for Integer Programming}},
  year   = {2021}
}

@misc{unknown-author-2018,
	title = {{Introduction to RL}},
	year = {2018},
	url = {https://spinningup.openai.com/en/latest/user/introduction.html},
}
@book{puterman-1994,
	author = {Puterman, Martin L.},
	month = {4},
	title = {{Markov Decision processes}},
	year = {1994},
	doi = {10.1002/9780470316887},
	url = {https://doi.org/10.1002/9780470316887},
}

@article{mnih-2013,
  title={Playing Atari with Deep Reinforcement Learning},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013},
  url={https://arxiv.org/abs/1312.5602}
}

@misc{sanz2024dqn,
  author       = {Markel Sanz},
  title        = {Introduction to Reinforcement Learning (Part 3): Q-Learning with Neural Networks Algorithm (DQN)},
  year         = {2024},
  howpublished = {\url{https://markelsanz14.medium.com/introduction-to-reinforcement-learning-part-3-q-learning-with-neural-networks-algorithm-dqn-1e22ee928ecd}},
  note         = {Accessed: 2024-12-03}
}

@inproceedings{silver2014deterministic,
  title={Deterministic Policy Gradient Algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={Proceedings of the 31st International Conference on Machine Learning (ICML)},
  year={2014},
  publisher={PMLR}
}

@misc{lillicrap2019continuouscontroldeepreinforcement,
      title={Continuous control with deep reinforcement learning}, 
      author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
      year={2015},
      eprint={1509.02971},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1509.02971}, 
}