
@book{10.5555/1795711,
  author    = {Millington, Ian and Funge, John},
  title     = {Artificial Intelligence for Games, Second Edition},
  year      = {2009},
  isbn      = {0123747317},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA},
  edition   = {2nd},
  abstract  = {Creating robust artificial intelligence is one of the greatest challenges for game developers, yet the commercial success of a game is often dependent upon the quality of the AI. In this book, Ian Millington brings extensive professional experience to the problem of improving the quality of AI in games. He describes numerous examples from real games and explores the underlying ideas through detailed case studies. He goes further to introduce many techniques little used by developers today. The book's associated web site contains a library of C++ source code and demonstration programs, and a complete commercial source code library of AI algorithms and techniques."Artificial Intelligence for Games - 2nd edition" will be highly useful to academics teaching courses on game AI, in that it includes exercises with each chapter. It will also include new and expanded coverage of the following: AI-oriented gameplay; Behavior driven AI; Casual games (puzzle games). * The first comprehensive, professional tutorial and reference to implement true AI in games written by an engineer with extensive industry experience.* Walks through the entire development process from beginning to end.* Includes examples from over 100 real games, 10 in-depth case studies, and web site with sample code.}
}

@techreport{tang-2021,
  author = {Tang, Yunhao},
  title  = {{Reinforcement Learning: New Algorithms and An Application for Integer Programming}},
  year   = {2021}
}

@misc{unknown-author-2018,
  title = {{Introduction to RL}},
  year  = {2018},
  url   = {https://spinningup.openai.com/en/latest/user/introduction.html}
}
@book{puterman-1994,
  author = {Puterman, Martin L.},
  month  = {4},
  title  = {{Markov Decision processes}},
  year   = {1994},
  doi    = {10.1002/9780470316887},
  url    = {https://doi.org/10.1002/9780470316887}
}


@misc{sanz2024dqn,
  author       = {Markel Sanz},
  title        = {Introduction to Reinforcement Learning (Part 3): Q-Learning with Neural Networks Algorithm (DQN)},
  year         = {2024},
  howpublished = {\url{https://markelsanz14.medium.com/introduction-to-reinforcement-learning-part-3-q-learning-with-neural-networks-algorithm-dqn-1e22ee928ecd}},
  note         = {Accessed: 2024-12-03}
}

@article{article,
  author  = {Diederichs, Elmar},
  year    = {2019},
  month   = {08},
  pages   = {25},
  title   = {Reinforcement Learning - A Technical Introduction},
  volume  = {2},
  journal = {Journal of Autonomous Intelligence},
  doi     = {10.32629/jai.v2i2.45}
}
@online{ddpg_explained,
  author  = {Chris Yoon},
  title   = {Deep Deterministic Policy Gradients Explained},
  year    = {2019},
  url     = {https://towardsdatascience.com/deep-deterministic-policy-gradients-explained-2d94655a9b7b},
  urldate = {2024-12-04},
  note    = {Towards Data Science}
}
@misc{pygame,
  author = {Pygame Community},
  title = {Pygame},
  year = {2024},
  url = {https://www.pygame.org/news},
  note = {Accessed: 2024-07-29}
}

@online{stanford_cs234,
  title        = {Reinforcement Learning Winter 2019},
  author       = {Emma Brunskill},
  year         = {2019},
  url          = {https://youtu.be/FgzM3zpZ55o},
  organization = {Stanford University},
  urldate      = {2024-07-06}
}

@online{snake_game,
  title        = {Snake Game in Python Using Pygame Module},
  organization = {GeeksforGeeks},
  year         = {2024},
  url          = {https://www.geeksforgeeks.org/snake-game-in-python-using-pygame-module/},
  urldate      = {2024-07-29}
}

@online{numpy_docs,
  title        = {NumPy Documentation},
  organization = {NumPy},
  year         = {2024},
  url          = {https://numpy.org/},
  urldate      = {2024-09-20}
}

@online{python_docs,
  title        = {Python Documentation},
  organization = {Python Software Foundation},
  year         = {2024},
  url          = {https://www.python.org},
  urldate      = {2024-07-29}
}

@online{ml_types,
  title        = {Types of Machine Learning},
  organization = {GeeksforGeeks},
  year         = {2024},
  url          = {https://www.geeksforgeeks.org/types-of-machine-learning/},
  urldate      = {2024-08-03}
}

@online{ml_unsupervised,
  title        = {Unsupervised Machine Learning: The Future of Cybersecurity},
  organization = {GeeksforGeeks},
  year         = {2024},
  url          = {https://www.geeksforgeeks.org/unsupervised-machine-learning-the-future-of-cybersecurity/},
  urldate      = {2024-08-03}
}

@online{spinning_up,
  title        = {Spinning Up in Deep Reinforcement Learning},
  organization = {OpenAI},
  year         = {2024},
  url          = {https://spinningup.openai.com/en/latest/index.html},
  urldate      = {2024-08-05}
}

@online{matplotlib_docs,
  title        = {Matplotlib Documentation},
  organization = {Matplotlib Development Team},
  year         = {2024},
  url          = {https://matplotlib.org/stable/},
  urldate      = {2024-09-27}
}

@online{pytorch_docs,
  title        = {PyTorch Documentation},
  organization = {PyTorch},
  year         = {2024},
  url          = {https://pytorch.org/},
  urldate      = {2024-10-24}
}

@online{pytorch_rl,
  title        = {Reinforcement Learning (DQN) Tutorial},
  organization = {PyTorch},
  year         = {2024},
  url          = {https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html},
  urldate      = {2024-10-24}
}

@article{delayed_rewards,
  title     = {Learning From Delayed Rewards},
  author    = {Watkins, Christopher},
  year      = {1989},
  publisher = {King's College, Cambridge},
  url       = {https://www.researchgate.net/publication/33784417_Learning_From_Delayed_Rewards},
  urldate   = {2024-11-17}
}

@article{multi_agent_rl,
  title   = {Cooperation Between Multiple Agents Based on Partially Sharing Policy},
  year    = {2024},
  url     = {https://www.researchgate.net/publication/220776448_Cooperation_Between_Multiple_Agents_Based_on_Partially_Sharing_Policy},
  urldate = {2024-11-17}
}

@online{nn_math,
  title        = {The Mathematics of Neural Network},
  organization = {Medium},
  publisher    = {Coinmonks},
  year         = {2024},
  url          = {https://medium.com/coinmonks/the-mathematics-of-neural-network-60a112dd3e05},
  urldate      = {2024-11-29}
}

@article{ddpg,
  title   = {Continuous Control with Deep Reinforcement Learning},
  author  = {Lillicrap, Timothy P. and others},
  journal = {arXiv preprint arXiv:1509.02971},
  year    = {2015},
  url     = {https://arxiv.org/abs/1509.02971},
  urldate = {2024-11-31}
}

@article{silver_dpg,
  title     = {Deterministic Policy Gradient Algorithms},
  author    = {Silver, David and others},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning},
  year      = {2014},
  url       = {https://proceedings.mlr.press/v32/silver14.pdf},
  urldate   = {2024-11-31}
}

@online{wiki_rl,
  title        = {Reinforcement learning},
  organization = {Wikipedia},
  year         = {2024},
  url          = {https://en.wikipedia.org/wiki/Reinforcement_learning},
  urldate      = {2024-09-03}
}

@online{scribbr_rl,
  title        = {Reinforcement Learning Uitgelegd},
  organization = {Scribbr},
  year         = {2024},
  url          = {https://www.scribbr.nl/ai-tools-gebruiken/reinforcement-learning-uitgelegd/},
  urldate      = {2024-09-04}
}

@online{geeksforgeeks_rl,
  title        = {What is Reinforcement Learning?},
  organization = {GeeksforGeeks},
  year         = {2024},
  url          = {https://www.geeksforgeeks.org/what-is-reinforcement-learning/},
  urldate      = {2024-09-05}
}

@online{oracle_rl,
  title        = {What is Reinforcement Learning?},
  organization = {Oracle},
  year         = {2024},
  url          = {https://www.oracle.com/nl/artificial-intelligence/machine-learning/reinforcement-learning/},
  urldate      = {2024-09-06}
}

@online{ai_basics,
  title        = {Artificial Intelligence 101: The Basics of AI},
  organization = {Atlassian},
  year         = {2024},
  url          = {https://www.atlassian.com/blog/artificial-intelligence/artificial-intelligence-101-the-basics-of-ai},
  urldate      = {2024-08-30}
}

@online{datacamp_ai,
  title        = {What is AI? Quick Start Guide for Beginners},
  organization = {DataCamp},
  year         = {2024},
  url          = {https://www.datacamp.com/blog/what-is-ai-quick-start-guide-for-beginners},
  urldate      = {2024-08-30}
}

@online{analytics_vidhya_rl,
  title        = {Introduction to Reinforcement Learning for Beginners},
  organization = {Analytics Vidhya},
  year         = {2024},
  url          = {https://www.analyticsvidhya.com/blog/2021/02/introduction-to-reinforcement-learning-for-beginners/},
  urldate      = {2024-09-03}
}

@online{rl_guide,
  title        = {The Ultimate Beginner's Guide to Reinforcement Learning},
  organization = {Towards Data Science},
  year         = {2024},
  url          = {https://towardsdatascience.com/the-ultimate-beginners-guide-to-reinforcement-learning-588c071af1ec},
  urldate      = {2024-09-03}
}

@online{q_learning_tutorial,
  title        = {What is Q-Learning: A Tutorial},
  organization = {Simplilearn},
  year         = {2024},
  url          = {https://www.simplilearn.com/tutorials/machine-learning-tutorial/what-is-q-learning},
  urldate      = {2024-09-04}
}

@online{dqn_guide,
  title        = {Deep Q-Learning Explained: A Comprehensive Guide},
  organization = {Inoxoft},
  year         = {2024},
  url          = {https://inoxoft.com/blog/deep-q-learning-explained-a-comprehensive-guide/},
  urldate      = {2024-09-07}
}

@book{sutton_barto,
  title     = {Reinforcement Learning: An Introduction},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  edition   = {2},
  year      = {2018},
  publisher = {MIT Press},
  url       = {https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf},
  urldate   = {2024-09-07}
}

@article{dqn_paper,
  title   = {Playing Atari with Deep Reinforcement Learning},
  author  = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  year    = {2013},
  journal = {arXiv preprint arXiv:1312.5602},
  url     = {https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf},
  urldate = {2024-09-09}
}

@InProceedings{pmlr-v119-cobbe20a,
  title = 	 {Leveraging Procedural Generation to Benchmark Reinforcement Learning},
  author =       {Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {2048--2056},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/cobbe20a/cobbe20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/cobbe20a.html},
  abstract = 	 {We introduce Procgen Benchmark, a suite of 16 procedurally generated game-like environments designed to benchmark both sample efficiency and generalization in reinforcement learning. We believe that the community will benefit from increased access to high quality training environments, and we provide detailed experimental protocols for using this benchmark. We empirically demonstrate that diverse environment distributions are essential to adequately train and evaluate RL agents, thereby motivating the extensive use of procedural content generation. We then use this benchmark to investigate the effects of scaling model size, finding that larger models significantly improve both sample efficiency and generalization.}
}

@article{geveke2016,
  author       = {Geveke, M.},
  title        = {Van wereldoorlog naar wereldorde: Het Nederlandse leger en de Verenigde Naties},
  journal      = {Militaire Spectator},
  volume       = {185},
  number       = {7/8},
  year         = {2016},
  pages        = {340--352},
  url          = {https://militairespectator.nl/sites/default/files/teksten/bestanden/MS%2078-2016%20Geveke.pdf},
}
